'use strict';(function(){const t={cache:!0};t.doc={id:"id",field:["title","content"],store:["title","href","section"]};const e=FlexSearch.create("balance",t);window.bookSearchIndex=e,e.add({id:0,href:"/docs/data-engineering/",title:"Data Engineering Introduction",section:"Docs",content:"Data Engineering Introduction #  This is a note with an important message\n First there was files. Files as far as the eye could see. Data in CSV and XML. Then Excel came along. If you were fancy you had mainframes.\nThen came the relational database renaissance. Everyone writes SQL and puts all their data in Oracle, MySQL, PostgreSQL, or SQL Server.\nNext people wanted to consolidate all their data into a Data Warehouse. MPP platforms like Teradata, Netezza, and Oracle DW.\nHadoop burst onto the scene with cluster computing. Hadoop distributed file system. Map Reduce\nCloud offered a new way with managed services. Separation of storage and compute.\nMPP - Massively Parallel Processing SQL - Structured Query Language NoSQL - Literally No SQL or ‚ÄúNot Only SQL‚Äù. Examples include key/value stores like Redis, wide column dbs like Cassandra and HBase.\nVolume - The quantity of generated and stored data. Big Data is typically when you have so much data you can‚Äôt store/process it effectively on one machine\nVariety - The type and nature of the data. Example: files like CSV, structured data in databases, audio, videos, sensor readings, logs\nVelocity - the speed at which the data is generated and processed Batch (once a day, import a file into the database), Streaming 24/7 process transactions looking for fraud\nVariability - Inconsistency of the data set can hamper processes to handle and manage it. Do the values in the dataset mean the same thing? Example: free text notes field where someone enters a value, email addresses, names\nVeracity - The quality of captured data can vary greatly, Trustworthiness of the data\n"}),e.add({id:1,href:"/docs/getting-started/",title:"Getting Started",section:"Docs",content:"Getting Started #  Get you and your computer ready!\nPre-requisites #  Data Engineers often work with the command line as part of their job. We\u0026rsquo;ll use the command line a few times throughout this course.\n REQUIRED: Start with the basics üëâ Command line basics Starting with Kafka, you\u0026rsquo;ll also need to know How to Set Environment Variables  Setup your Computer #  To run these examples, you need an environment capable of running an IDE (Intellij) which means a modern CPU and at least 4GB of RAM.\nClone the Hours with Experts repository\nhttps://github.com/1904labs/streaming-data-pipeline\nInstalling Software #  To start we\u0026rsquo;ll need to download and install git\nhttps://git-scm.com/downloads\nInstalling Intellij IDEA #  Download and install Intellij IDEA Community Edition from the website\nWindows: https://www.jetbrains.com/idea/download/#section=windows\nMac: https://www.jetbrains.com/idea/download/#section=mac\nFrom the home screen, click \u0026ldquo;Plugins\u0026rdquo; and go to Marketplace.\nFind and install the Scala plugin.\nRestart the IDE\nOpen the scala-hello-world project\nClick Open as Project.\nClick Trust Project.\nIf you don\u0026rsquo;t have Java installed, you can install it through IntelliJ. Click on File -\u0026gt; Project Structure.\nUnder Platform Settings click SDKs. Click the \u0026ldquo;+\u0026rdquo; sign and choose Download SDK.\nFor version, select 1.8 and anything you want for vendor (Amazon Corretto works well).\nClick OK to save.\nAfter installing the JDK for the first time, Intellij may be a little confused. You can refresh the maven project by opening the Maven tool window and clicking the \u0026ldquo;Reload all Maven Projects\u0026rdquo; button.\nSanity check: Run the Scala App #  In the scala-hello-world project (that you cloned as part of streaming-data-pipeline) open App.scala by navigating down src/main/scala/com.labs.hwe.\nRun the project by clicking the green arrow next to App. Verify that you see \u0026ldquo;Hello World\u0026rdquo; in the output.\nInstalling Git on Mac #  Your mac should come with git already! Check by opening up the terminal and typing\ngit --version If all goes well, you\u0026rsquo;ll see something like this:\n"}),e.add({id:2,href:"/docs/scala/",title:"Scala",section:"Docs",content:"Scala #  Scala introduction.\nTODO\n"}),e.add({id:3,href:"/docs/kafka/",title:"Kafka",section:"Docs",content:"Kafka #  Spark introduction.\nTODO\n"}),e.add({id:4,href:"/docs/spark/",title:"Spark",section:"Docs",content:"Spark #  Spark introduction.\nTODO\n\u0026lt;section id=\u0026#34;main\u0026#34;\u0026gt;  \u0026lt;div\u0026gt;  \u0026lt;h1 id=\u0026#34;title\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt;  {{ range .Pages }}  {{ .Render \u0026#34;summary\u0026#34;}}  {{ end }}  \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; "}),e.add({id:5,href:"/docs/spark-and-kafka/",title:"Spark and Kafka",section:"Docs",content:"Using Kafka with Spark #  How to read from Kafka in Spark introduction.\nTODO\n"}),e.add({id:6,href:"/docs/hbase/",title:"HBase",section:"Docs",content:"HBase #  HBase introduction.\nTODO\n"}),e.add({id:7,href:"/docs/spark-and-hbase/",title:"Spark and HBase",section:"Docs",content:"Using HBase with Spark #  How to query HBase from Spark introduction.\nTODO\n"})})()